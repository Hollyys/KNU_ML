{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/AliaksandrSiarohin/first-order-model/blob/master/old_demo.ipynb","timestamp":1695182914470}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["#!/usr/bin/env python\n","# coding: utf-8\n","\n","# Python ≥3.5 is required\n","import sys\n","assert sys.version_info >= (3, 5)\n","\n","# Scikit-Learn ≥0.20 is required\n","import sklearn\n","assert sklearn.__version__ >= \"0.20\"\n","\n","# Common imports\n","import numpy as np\n","import os"],"metadata":{"id":"nEXGgmiPKOl-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# to make this notebook's output stable across runs\n","np.random.seed(42)\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import make_moons\n","import matplotlib.pyplot as plt\n","\n","X, y = make_moons(n_samples=3000, noise=0.2, random_state=42)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n","\n","print(\"Trainset: {}, Testset: {}\".format(X_train.shape, y_train.shape))\n","\n","plt.scatter(X_train[:, 0], X_train[:, 1], marker='.', c=y_train, s=100,\n","            edgecolor=\"k\", linewidth=1)\n","plt.xlabel(\"$X_1$\")\n","plt.ylabel(\"$X_2$\")\n","plt.show()\n","\n","plt.scatter(X_test[:, 0], X_test[:, 1], marker='.', c=y_test, s=100,\n","            edgecolor=\"k\", linewidth=1)\n","plt.xlabel(\"$X_1$\")\n","plt.ylabel(\"$X_2$\")\n","plt.show()\n","\n","'''\n","plt.scatter(X_train[:, 1], X_train[:, 2], marker='.', c=y_train, s=100,\n","            edgecolor=\"k\", linewidth=1)\n","plt.xlabel(\"$X_1$\")\n","plt.ylabel(\"$X_2$\")\n","plt.show()\n","\n","plt.scatter(X_train[:, 0], X_train[:, 2], marker='.', c=y_train, s=100,\n","            edgecolor=\"k\", linewidth=1)\n","plt.xlabel(\"$X_1$\")\n","plt.ylabel(\"$X_2$\")\n","plt.show()\n","'''"],"metadata":{"id":"3Q8OUIPsL2TA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.linear_model import SGDClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.ensemble import BaggingClassifier\n","from sklearn.ensemble import AdaBoostClassifier\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import LinearSVC\n","\n","def get_models(r_state=42, n_est=50, lr=0.1):\n","    models = dict()\n","    models['log'] =  LogisticRegression(solver=\"lbfgs\", random_state=42)\n","    models['sgd']= SGDClassifier(loss=\"hinge\", learning_rate=\"constant\",\n","                                 eta0=0.001, max_iter=10000, tol=1e-3,\n","                                 random_state=r_state)\n","    models['dt'] = DecisionTreeClassifier(random_state=r_state)\n","    models['rf'] = RandomForestClassifier(\n","                                          random_state=r_state)\n","    models['lsvm'] = SVC(kernel=\"linear\", random_state=r_state)\n","    models['polsvm'] = Pipeline([\n","        (\"poly_features\", PolynomialFeatures(degree=10)),\n","        (\"scaler\", StandardScaler()),\n","        (\"svm_clf\", LinearSVC(C=10, loss=\"hinge\", random_state=42))\n","    ])\n","    models['vote'] = VotingClassifier(\n","        estimators=[('log', models['log']),\n","                    ('sgd', models['sgd']),\n","                    ('rf', models['rf']),\n","                    ('polsvm', models['polsvm'])],\n","        voting='hard')\n","    models['bag'] = BaggingClassifier(\n","        DecisionTreeClassifier(random_state=r_state), n_estimators=n_est,\n","        bootstrap=True, random_state=r_state)\n","    models['adab'] = AdaBoostClassifier(\n","        DecisionTreeClassifier(random_state=r_state), n_estimators=n_est,\n","        algorithm=\"SAMME.R\", learning_rate=lr, random_state=r_state)\n","    models['grab'] = GradientBoostingClassifier(\n","        random_state=r_state)\n","\n","    return models"],"metadata":{"id":"04T_GgHnL8zK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","import time\n","\n","def evaluate_model(model, X_train, X_test, y_train, y_test):\n","    start = time.time()\n","\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","\n","    elaptime = time.time() - start\n","    acc = accuracy_score(y_test, y_pred)\n","    return acc, elaptime\n","\n","models = get_models()\n","\n","results, names, times = list(), list(), list()\n","for name, model in models.items():\n","    acc, elaptime = evaluate_model(model, X_train, X_test,\n","                                   y_train, y_test)\n","    results.append(acc)\n","    times.append(elaptime)\n","    names.append(name)\n","    print('%s\\t %.4f (time: %.3f)' % (name, acc, elaptime))"],"metadata":{"id":"LUcW1HXyMBy9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.ensemble import StackingClassifier\n","\n","def get_stacking(models, nfold=5):\n","    layer0 = list()\n","    layer0.append(('sgd', models['sgd']))\n","    layer0.append(('rf', models['rf']))\n","    layer0.append(('polsvm', models['polsvm']))\n","    layer0.append(('adab', models['adab']))\n","    layer0.append(('grab', models['grab']))\n","    layer1 = LogisticRegression()\n","\n","    model = StackingClassifier(estimators=layer0,\n","                              final_estimator=layer1,\n","                              cv=nfold)\n","    return model\n","\n","\n","modelstack = dict()\n","modelstack['stack'] = get_stacking(models)\n","\n","results, names, times = list(), list(), list()\n","for name, model in modelstack.items():\n","    acc, elaptime = evaluate_model(model, X_train, X_test,\n","                                   y_train, y_test)\n","    results.append(acc)\n","    times.append(elaptime)\n","    names.append(name)\n","    print('%s\\t %.4f (time: %.3f)' % (name, acc, elaptime))"],"metadata":{"id":"2zl2xLcCMxIs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["########################\n","##### YOUR METHOD ######\n","########################\n","# MUST: You should capture the below function in the report!\n","def get_stacking2(models, nfold=5):\n","    layer0 = list()\n","    ### append your chosen models as many as you want\n","    layer0.append(('★★★', models['★★★']))\n","    layer0.append(('★★★', models['★★★']))\n","    layer0.append(('★★★', models['★★★']))\n","    layer0.append(('★★★', models['★★★']))\n","\n","    ### You can change layer1 if you are interested in though it is not recommended cuz it's hard work\n","    layer1 = LogisticRegression()\n","\n","    model = StackingClassifier(estimators=layer0,\n","                              final_estimator=layer1,\n","                              cv=nfold)\n","    return model"],"metadata":{"id":"1_OwPOZCM2F2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["modelstack = dict()\n","modelstack['your_stack'] = get_stacking2(models)\n","\n","your_results, your_names, your_times = list(), list(), list()\n","for name, model in modelstack.items():\n","    acc, elaptime = evaluate_model(model, X_train, X_test,\n","                                   y_train, y_test)\n","    your_results.append(acc)\n","    your_times.append(elaptime)\n","    your_names.append(name)\n","\n","print('%s\\t %.4f (time: %.3f)' % (str(your_names[0]), float(your_results[0]), float(your_times[0])))\n","\n","## checking/printing whether yours is better or not\n","diff = float(your_results[0]) - float(results[0])\n","dtime = float(times[0]) - float(your_times[0])\n","if diff > 0:\n","  print(\"Success:\\n\")\n","  print('%s is better than anchor at acc %.4f (saving time: %.3f s)'\n","        % (str(your_names), diff,dtime ))\n","else:\n","  print(\"Failed\")\n","# MUST: You should capture the below running result in the report!"],"metadata":{"id":"uGFAE-muM4si"},"execution_count":null,"outputs":[]}]}